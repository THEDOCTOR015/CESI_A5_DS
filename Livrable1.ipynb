{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as r\n",
    "import tensorflow.keras.layers as layers\n",
    "import tf.keras.callbacks as callbacks\n",
    "from tf.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset depuis Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 1: Monter Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Étape 2: Installer unrar (si nécessaire, dépend de l'environnement Colab actuel)\n",
    "!apt-get install unrar\n",
    "\n",
    "# Étape 3: Décompresser le fichier .rar\n",
    "!unrar x \"/content/drive/My Drive/Dataset_cesi.rar\" \"/content/Dataset_cesi/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH_NO_PHOTO_FOLDERS = ['Dataset_cesi/Painting', 'Dataset_cesi/Schematics', 'Dataset_cesi/Text', 'Dataset_cesi/Sketch']\n",
    "PATH_NO_PHOTO_FOLDERS = ['Dataset_cesi/Schematics']\n",
    "PATH_PHOTO_FOLDER = 'Dataset_cesi/Photo'\n",
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "CHANNELS = 3\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.05\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métrics du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution de la taille des images ( 80s )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_sizes(folder_path):\n",
    "    heights = []\n",
    "    widths = []\n",
    "    \n",
    "    # Parcourir le dossier et lire chaque image\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            with Image.open(img_path) as img:\n",
    "                width, height = img.size\n",
    "                widths.append(width)\n",
    "                heights.append(height)\n",
    "    \n",
    "    # Afficher les distributions des largeurs et hauteurs\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(widths, bins=20, color='blue', alpha=0.7)\n",
    "    plt.title('Distribution des largeurs')\n",
    "    plt.xlabel('Largeur')\n",
    "    plt.ylabel('Nombre d\\'images')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(heights, bins=20, color='green', alpha=0.7)\n",
    "    plt.title('Distribution des hauteurs')\n",
    "    plt.xlabel('Hauteur')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_image_sizes(PATH_PHOTO_FOLDER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Informations sur les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_info(folder):\n",
    "    images = os.listdir(folder)\n",
    "    length = len(images)\n",
    "    return length\n",
    "# Dossier photo\n",
    "photo_length = get_folder_info(PATH_PHOTO_FOLDER)\n",
    "print(f'Nombre d\\'images dans le dossier photo: {photo_length}')\n",
    "\n",
    "# Dossiers sans photo\n",
    "no_photo_len = 0\n",
    "no_photo_folders_len = []\n",
    "for folder in PATH_NO_PHOTO_FOLDERS:\n",
    "    no_photo_folder_len = get_folder_info(folder)\n",
    "    no_photo_len += no_photo_folder_len\n",
    "    no_photo_folders_len.append(no_photo_folder_len)\n",
    "print(f'Nombre d\\'images dans les dossiers sans photo: {no_photo_len}')\n",
    "for i in range(len(PATH_NO_PHOTO_FOLDERS)):\n",
    "    print(f'Nombre d\\'images dans le dossier {PATH_NO_PHOTO_FOLDERS[i]}: {no_photo_folders_len[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(list_path_nophoto,path_photo):\n",
    "    def load_folder(path_folder, label):\n",
    "        # label = 0 pour les images sans photo, 1 pour les images avec photo\n",
    "        data_folder = []\n",
    "        label_folder = []\n",
    "        for filename in os.listdir(path_folder):\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(path_folder, filename)\n",
    "                with Image.open(img_path) as img:\n",
    "                    img = img.resize((WIDTH, HEIGHT)) # Avoir la même taille\n",
    "                    img = img.convert('RGB') # Avoir 3 channels\n",
    "                    #img = np.array(img)\n",
    "                    data_folder.append(img)\n",
    "                    label_folder.append(label)\n",
    "        data_folder = np.array(data_folder)\n",
    "        label_folder = np.array(label_folder)\n",
    "        return data_folder, label_folder\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    # On ajoute les images avec photo\n",
    "    data_folder, label_folder = load_folder(path_photo, 1)\n",
    "    x.append(data_folder)\n",
    "    y.append(label_folder)\n",
    "    \n",
    "    print(f'chargement des images avec photo: {data_folder.shape}')\n",
    "    print(f'chargement des labels avec photo: {label_folder.shape}')\n",
    "    \n",
    "    # On ajoute les images sans photo\n",
    "    for path_folder in list_path_nophoto:\n",
    "        data_folder, label_folder = load_folder(path_folder, 0)\n",
    "        x.append(data_folder)\n",
    "        y.append(label_folder)\n",
    "        print(f' Dataset : {path_folder} chargé avec {data_folder.shape} images')\n",
    "        print(f' Labels : {path_folder} chargé avec {label_folder.shape} labels')\n",
    "    \n",
    "    x = np.concatenate(x)\n",
    "    y = np.concatenate(y)\n",
    "    return x, y\n",
    "    \n",
    "# On charge le dataset\n",
    "x, y = load_dataset(PATH_NO_PHOTO_FOLDERS, PATH_PHOTO_FOLDER)\n",
    "\n",
    "print('Charge du dataset terminée')\n",
    "\n",
    "# On mélange les données\n",
    "indices = np.arange(x.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "print('Mélange des données terminé')\n",
    "\n",
    "# On divise le dataset en train, validation et test\n",
    "def split_dataset(x, y, train_ratio=TRAIN_RATIO, val_ratio=VAL_RATIO, test_ratio=TEST_RATIO):\n",
    "    assert train_ratio + val_ratio + test_ratio == 1\n",
    "    train_size = int(x.shape[0] * train_ratio)\n",
    "    val_size = int(x.shape[0] * val_ratio)\n",
    "    x_train = x[:train_size]\n",
    "    y_train = y[:train_size]\n",
    "    x_val = x[train_size:train_size+val_size]\n",
    "    y_val = y[train_size:train_size+val_size]\n",
    "    x_test = x[train_size+val_size:]\n",
    "    y_test = y[train_size+val_size:]\n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
    "\n",
    "data_train, data_val, data_test = split_dataset(x, y)\n",
    "\n",
    "print(f'Données d\\'entrainement: {data_train[0].shape}')\n",
    "print(f'Données de validation: {data_val[0].shape}')\n",
    "print(f'Données de test: {data_test[0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Sélectionner un index aléatoire\n",
    "random_index = r.randint(0, len(x) - 1)\n",
    "\n",
    "# Récupérer l'image et le label correspondants\n",
    "random_image = x[random_index]\n",
    "random_label = 'Photo' if y[random_index] == 1 else 'No photo'\n",
    "\n",
    "\n",
    "# Afficher l'image avec son label\n",
    "plt.imshow(random_image)\n",
    "plt.title(f'Label: {random_label}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charement d'un modèle préexistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(\"Librable1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    layers.BatchNormalization(input_shape=(HEIGHT, WIDTH, CHANNELS)),\n",
    "    layers.Conv2D(32, (3, 3), activation='leaky_relu', padding='same', strides=2),\n",
    "    layers.Conv2D(64, (3, 3), activation='leaky_relu', padding='same', strides=2),\n",
    "    layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same', strides=2),\n",
    "    layers.Conv2D(256, (3, 3), activation='leaky_relu', padding='same', strides=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='leaky_relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback d'early stopping\n",
    "early_callback = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Cycle d'entrainement\n",
    "history = model.fit(data_train[0], data_train[1], batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(data_val[0], data_val[1]), callbacks=[early_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Courbe d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Librable1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions sur les données de test\n",
    "y_pred = model.predict(data_test[0])\n",
    "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calcul de la matrice de confusion\n",
    "cm = confusion_matrix(data_test[1], y_pred_classes)\n",
    "\n",
    "# Affichage de la matrice de confusion\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No photo', 'Photo'], yticklabels=['No photo', 'Photo'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test unitaire sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Sélectionner un index aléatoire dans l'ensemble de test\n",
    "random_index_test = r.randint(0, len(data_test[0]) - 1)\n",
    "\n",
    "# Récupérer l'image et le label correspondant\n",
    "random_image_test = data_test[0][random_index_test]\n",
    "true_label = 'Photo' if data_test[1][random_index_test] == 1 else 'No photo'\n",
    "\n",
    "# Faire l'inférence avec le modèle\n",
    "predicted_label = 'Photo' if model.predict(np.expand_dims(random_image_test, axis=0))[0][0] > 0.5 else 'No photo'\n",
    "\n",
    "# Afficher l'image avec son label réel et prédit\n",
    "plt.imshow(random_image_test)\n",
    "plt.title(f'True Label: {true_label}\\nPredicted Label: {predicted_label}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
