{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIVRABLE 1 - PROJET OPTION DATA SCIENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LUCA Alexandre - GIRAUDEAU Valentin - BEN FREDJ Skander"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexte\n",
    "\n",
    "TouNum est une entreprise spécialisée dans la numérisation de documents papier en format numérique, qu'il s'agisse de textes, d'images, ou d'autres types de données visuelles. Leurs services sont souvent utilisés par d'autres entreprises qui ont besoin de digitaliser de grandes quantités de documents. Grâce aux avancées des technologies de Machine Learning et d'intelligence artificielle, TouNum souhaite évoluer et offrir des services plus complets, notamment l'analyse et la classification automatique d'images et la génération automatique de légendes descriptives (image captioning).\n",
    "\n",
    "Les documents numérisés par TouNum sont variés : certaines images représentent des photographies, tandis que d'autres peuvent être des schémas, des dessins ou des scans de textes. L'objectif est de traiter ces données de manière efficace et d'automatiser les processus d'analyse afin de gagner en productivité et en précision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enjeux du projet\n",
    "\n",
    "Le but de ce projet de fournir un prototype d'intelligence artificielle basé sur les réseaux de neuronnes pour classifier des images selon leur type (dessin, schéma, photo, etc) malgré leur qualité (floue, bruitée, etc) tout en apportant une légende pour chacune des images, et ceci de façon automatique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectifs du projet\n",
    "\n",
    "Pour atteindre l'enjeux principal du projet, l'entreprise TouNum nous a sollicité pour concevoir un prototype capable de relever plusieurs défis :\n",
    "\n",
    "    - Nettoyage et prétraitement des images : les images numérisées peuvent être de qualité variable (bruitées, floues, etc.), nécessitant l'utilisation de techniques de traitement d'image pour améliorer leur qualité avant toute analyse.\n",
    "\n",
    "    - Classification automatique : il est crucial de pouvoir distinguer les différentes catégories d'images. L'algorithme doit être capable de différencier des photos d'autres types d'images comme des schémas ou des dessins.\n",
    "\n",
    "    - Génération automatique de légendes (captioning) : une fois les images catégorisées, le système devra être en mesure de générer automatiquement une légende descriptive pour les photos. Cela implique l'utilisation de modèles avancés de Machine Learning comme les réseaux de neurones convolutifs (CNN) pour l'analyse visuelle et les réseaux récurrents (RNN) pour la génération de texte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organisation\n",
    "\n",
    "Le travail effectué dans ce projet sera présenté en 3 rapports au format jupyter notebook (.ipynb) et une présentation finale. Dans ce premier document, il est question de présenter uniquement notre modèle de classification binaire. Cela comprend : \n",
    "\n",
    "    - Le code TensorFlow ainsi qu'un schéma de l'architecture du réseau de neurones. Toutes les parties doivent être détaillée dans le notebook : les paramètre du réseau, la fonction de perte ainsi que l'algorithme d'optimisation utilisé pour l’entraînement.\n",
    "\n",
    "    - Un graphique contenant l'évolution de l'erreur d’entraînement ainsi que de l'erreur de test et l'évolution de l'accuracy pour ces deux datasets.\n",
    "\n",
    "    - L'analyse de ces résultats, notamment le compromis entre biais et variance (ou sur-apprentissage et sous-apprentissage).\n",
    "\n",
    "    - Une description des méthodes potentiellement utilisables pour améliorer les compromis biais/variance : technique de régularisation, drop out, early-stopping, ...\n",
    "\n",
    "Le but étant pour notre modèle, d'être capable de distinguer les photos parmi toutes ces images.\n",
    "\n",
    "Du point de vue de l'équipe, nous nous sommes organisés à l'aide d'outils comme Trello pour la gestion et répartition des tâches et également un serveur Discord pour la communication et le partage d'informations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mon Image](https://raw.githubusercontent.com/THEDOCTOR015/CESI_A5_DS/refs/heads/main/livrable1_diag.png?token=GHSAT0AAAAAACWP4J76DFVKFJG6RPNRUB3YZYJVAOA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "La partie imports consiste à ajouter des fonctionnalités déjà existantes pour faciliter notre travail sur la contruction de notre modèle et cela à travers certaines librairies ou datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as r\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "print(\"Répertoire de travail actuel :\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Détails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce premier bloc, on peut voir plusieurs importations de bibliothèques utiles pour le traitement d'images, l'apprentissage automatique avec TensorFlow, et d'autres utilitaires pour la visualisation et la manipulation de données.\n",
    "\n",
    "\"from PIL import Image\"\n",
    "    - PIL (Python Imaging Library) est une bibliothèque pour la manipulation d'images. Ici, le module Image est importé, ce qui permet de charger, manipuler et sauvegarder des images.\n",
    "\n",
    "\"import os\"\n",
    "    - os est une bibliothèque Python pour interagir avec le système d'exploitation, comme accéder aux fichiers, naviguer dans les répertoires, etc.\n",
    "\n",
    "\"import matplotlib.pyplot as plt\"\n",
    "    - matplotlib.pyplot est un sous-module de Matplotlib qui permet de créer des visualisations telles que des graphiques, des courbes, des images, etc. Le surnom plt est une convention courante utilisée pour rendre le code plus concis.\n",
    "\n",
    "\"import tensorflow as tf\"\n",
    "    - tensorflow est une bibliothèque très utilisée pour créer et entraîner des modèles de machine learning (en particulier des réseaux de neurones profonds). Ici, l'alias tf est utilisé pour rendre l'appel à TensorFlow plus court.\n",
    "\n",
    "\"import numpy as np\"\n",
    "    - numpy est une bibliothèque puissante pour la manipulation de tableaux multidimensionnels (appelés arrays) et l’exécution d'opérations mathématiques complexes sur ceux-ci.\n",
    "\n",
    "\"import random as r\"\n",
    "    - random est une bibliothèque pour générer des nombres aléatoires et effectuer des opérations aléatoires. Ici, l’alias r est utilisé pour simplifier les appels.\n",
    "\n",
    "\"import tensorflow.keras.layers as layers\"\n",
    "    - tensorflow.keras.layers contient une collection de couches (layers) pour construire des réseaux de neurones, comme des couches convolutives (Conv2D), des couches entièrement connectées (Dense), etc. L'alias layers est utilisé pour accéder plus facilement aux couches.\n",
    "\n",
    "\"import tensorflow.keras.callbacks as callbacks\"\n",
    "    - tensorflow.keras.callbacks contient des outils pour contrôler le processus d'entraînement des modèles.\n",
    "\n",
    "\"from tensorflow.keras.models import load_model\"\n",
    "    - load_model est une fonction pour charger un modèle de réseau de neurones sauvegardé (au format .h5 par exemple).\n",
    "\n",
    "\"from sklearn.metrics import confusion_matrix\"\n",
    "    - confusion_matrix est une fonction de sklearn (Scikit-learn) pour calculer la matrice de confusion, qui permet d'évaluer la performance d'un modèle de classification.\n",
    "\n",
    "\"import seaborn as sns\"\n",
    "    - seaborn est une bibliothèque basée sur Matplotlib qui simplifie la création de graphiques complexes. Elle est particulièrement utile pour visualiser des matrices de confusion ou des heatmaps.\n",
    "\n",
    "\"from tensorflow.keras.utils import Sequence\"\n",
    "    - Sequence est une classe utilitaire dans keras qui permet de créer des générateurs de données séquentielles, souvent utilisés pour charger des lots (batchs) de données lors de l'entraînement.\n",
    "\n",
    "Autre instruction : \n",
    "\n",
    "\"print(\"Répertoire de travail actuel :\", os.getcwd())\"\n",
    "    - Cette ligne utilise os.getcwd() pour afficher le chemin du répertoire de travail actuel (le répertoire à partir duquel le script est exécuté). Cela peut être utile pour vérifier l'environnement de travail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset depuis Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monter Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Installer unrar\n",
    "!apt-get install unrar\n",
    "\n",
    "# Décompresser le fichier .rar\n",
    "!unrar x \"/content/drive/My Drive/Dataset_cesi.rar\" \"/content/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Détails\n",
    "\n",
    "  \"drive.mount('/content/drive')\"  - Montage de Google Drive pour accéder aux fichiers dans un environnement Colab car notre dataset est stocké sur Google Drive.\n",
    "  <br>\"!apt-get install unrar\" - Installation de unrar pour décompresser des fichiers .rar si l'utilitaire n'est pas déjà présent.\n",
    "  <br>\"!unrar x \"/content/drive/My Drive/Dataset_cesi.rar\" \"/content/\"\"- Décompression d'une archive .rar depuis Google Drive vers le répertoire de travail de Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constantes et variables globales\n",
    "\n",
    "Les constantes et variables globales sont généralement définies au début du programme et sont accessibles pour l'ensemble du programme par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH_NO_PHOTO_FOLDERS = ['Dataset_cesi/Painting', 'Dataset_cesi/Schematics', 'Dataset_cesi/Text', 'Dataset_cesi/Sketch']\n",
    "PATH_NO_PHOTO_FOLDERS = ['Dataset_cesi/Schematics']\n",
    "PATH_PHOTO_FOLDER = 'Dataset_cesi/Photo'\n",
    "\n",
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "CHANNELS = 3\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.05\n",
    "assert TRAIN_RATIO + VAL_RATIO + TEST_RATIO  == 1\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 2\n",
    "\n",
    "START_TRAIN = 0\n",
    "STOP_TRAIN = TRAIN_RATIO\n",
    "START_VAL = TRAIN_RATIO\n",
    "STOP_VAL = START_VAL + VAL_RATIO\n",
    "START_TEST = STOP_VAL\n",
    "STOP_TEST = START_TEST + TEST_RATIO\n",
    "\n",
    "print(f'distribution => train : [{START_TRAIN}:{STOP_TRAIN}] val : [{START_VAL}:{STOP_VAL}]  test : [{START_TEST}:{STOP_TEST}]')\n",
    "\n",
    "indices = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Détails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"PATH_NO_PHOTO_FOLDERS\" - C'est une liste de chemins pointant vers des dossiers qui contiennent des images autres que des photos, comme des schémas. La ligne commentée montre que d'autres types d'images (peintures, croquis, textes) peuvent également être inclus, mais ici, seul le chemin vers les schémas est actif.\n",
    "<br>\"PATH_PHOTO_FOLDER\" - C'est le chemin vers le dossier contenant des photos.\n",
    "<br> \"HEIGHT\" et \"WIDTH\" - Ce sont les dimensions des images, qui seront redimensionnées à 256x256 pixels avant d'être utilisées pour l'entraînement d'un modèle de machine learning.\n",
    "<br> \"CHANNELS\" - Il indique que les images sont en couleurs (3 canaux : rouge, vert, bleu - RGB).\n",
    "<br> \"TRAIN_RATIO\" - Ce ratio (0.8) indique que 80% des données seront utilisées pour l'entraînement.\n",
    "<br> \"VAL_RATIO\" - Ce ratio (0.15) indique que 15% des données seront utilisées pour la validation.\n",
    "<br> \"TEST_RATIO\" - Ce ratio (0.05) indique que 5% des données seront utilisées pour les tests.\n",
    "<br> \"assert TRAIN_RATIO + VAL_RATIO + TEST_RATIO  == 1\" - Cette ligne vérifie que la somme des ratios d'entraînement, de validation et de test est bien égale à 1. Si ce n'est pas le cas, une erreur sera levée.\n",
    "<br> \"EPOCHS\" - Le nombre d'époques (ou itérations) que le modèle fera sur l'ensemble des données d'entraînement. Ici, il est fixé à 100.\n",
    "<br> \"BATCH_SIZE\" - La taille du batch est de 32, ce qui signifie que le modèle verra 32 exemples à la fois avant d'ajuster ses poids pendant l'entraînement.\n",
    "<br> \"PATIENCE\" - Il s'agit de la patience pour le callback d'arrêt anticipé. Si la performance du modèle ne s'améliore pas pendant 2 époques consécutives, l'entraînement peut s'arrêter avant la fin des 100 époques.\n",
    "<br> \"START_TRAIN\" et \"STOP_TRAIN\" - Il s'agit des indices pour l'ensemble d'entraînement qui vont de 0 à \"TRAIN_RATIO\" (donc de 0 à 0.8).\n",
    "<br> \"START_VAL\" et \"STOP_VAL\" - Il s'agit des indices pour l'ensemble de validation cette fois, et ils sont définis de \"TRAIN_RATIO\" (0.8) à \"TRAIN_RATIO + VAL_RATIO\" (0.95).\n",
    "<br> \"START_TEST\" et \"STOP_TEST\" - Ces derniers indices sont pour l'ensemble de test et ils vont de \"STOP_VAL\" (0.95) à 1.\n",
    "<br> \"print(f'distribution => train : [{START_TRAIN}:{STOP_TRAIN}] val : [{START_VAL}:{STOP_VAL}]  test : [{START_TEST}:{STOP_TEST}]')\" - Cette ligne affiche un résumé des plages d'indices pour les ensembles d'entraînement, de validation et de test. Cela permet de vérifier que la distribution des données est correcte avant de passer à l'entraînement du modèle.\n",
    "<br> \"indices = []\" Une liste vide appelée indices est initialisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Dans cette section, nous allons explorer le dataset utilisé pour entraîner notre futur modèle, en détaillant plusieurs aspects essentiels à son traitement. Tout d'abord, nous examinerons les métriques du dataset, notamment la distribution des tailles d'images et les informations spécifiques à chaque image. Ces statistiques permettent de mieux comprendre la structure des données avant de les manipuler. Ensuite, nous aborderons la création d'un générateur de dataset, qui facilitera le chargement et la transformation des images par lots, afin d'optimiser l'entraînement du modèle. Enfin, nous visualiserons les données, une étape essentielle pour s'assurer de la diversité et de la représentativité des images dans les différentes catégories du dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métriques du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution de la taille des images ( 80s )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_sizes(folder_path):\n",
    "    heights = []\n",
    "    widths = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            with Image.open(img_path) as img:\n",
    "                width, height = img.size\n",
    "                widths.append(width)\n",
    "                heights.append(height)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(widths, bins=20, color='blue', alpha=0.7)\n",
    "    plt.title('Distribution des largeurs')\n",
    "    plt.xlabel('Largeur')\n",
    "    plt.ylabel('Nombre d\\'images')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(heights, bins=20, color='green', alpha=0.7)\n",
    "    plt.title('Distribution des hauteurs')\n",
    "    plt.xlabel('Hauteur')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_image_sizes(PATH_PHOTO_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Détails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction \"analyze_image_sizes(folder_path)\" - La fonction accepte un argument, folder_path, qui correspond au chemin du dossier contenant les images à analyser. Son but est de parcourir toutes les images dans ce dossier et de collecter leurs dimensions (largeur et hauteur) pour les visualiser ensuite sous forme d'histogrammes.\n",
    "<br>\n",
    "<br> > Initialisation des listes pour stocker les tailles\n",
    "<br>\n",
    "<br> \"heights = []\" et \"widths = []\" - Liste \"heights\" pour stocker les hauteurs des images et liste \"widths\" pour stocker les largeurs des images.\n",
    "<br>\n",
    "<br> > Parcourir les fichiers dans le dossier\n",
    "<br>\n",
    "<br> \"for filename in os.listdir(folder_path)\" - La boucle parcourt tous les fichiers présents dans le dossier spécifié.\n",
    "<br> \"filename.lower().endswith(('.png', '.jpg', '.jpeg'))\" - Cela permet de ne traiter que les fichiers avec une extension d'image (ici .png, .jpg, .jpeg), en ignorant les autres fichiers.\n",
    "<br> \"img_path\" - Le chemin complet vers chaque image est construit en joignant \"folder_path\" et le nom du fichier.\n",
    "<br> \"Image.open(img_path)\" - La bibliothèque PIL (via Image) est utilisée pour ouvrir chaque image.\n",
    "<br> \"width, height = img.size\" - On récupère les dimensions de l'image (largeur et hauteur), qui sont ensuite ajoutées respectivement aux listes \"widths\" et \"heights\"\n",
    "<br>\n",
    "<br> > Visualisation des distributions des tailles\n",
    "<br>\n",
    "<br> \"plt.figure(figsize=(12, 6))\" - Créer une figure de 12 pouces de large et 6 pouces de haut, pour avoir un espace suffisant pour afficher les deux histogrammes côte à côte.\n",
    "<br> \"plt.subplot(1, 2, 1)\" - Créer la première sous-figure dans une grille de 1 ligne et 2 colonnes, pour l'histogramme des largeurs.\n",
    "<br> \"plt.hist(widths, bins=20, color='blue', alpha=0.7)\" - Créer un histogramme des largeurs avec 20 intervalles de classe (ou \"bins\"). L'argument color='blue' spécifie la couleur bleue et alpha=0.7 ajuste la transparence pour une meilleure lisibilité.\n",
    "<br> \"plt.title('Distribution des largeurs')\" - Définit le titre de ce premier histogramme.\n",
    "<br> \"plt.xlabel('Largeur')\" et \"plt.ylabel('Nombre d'images')\" - Définissent respectivement les labels des axes X et Y.\n",
    "<br> \"plt.subplot(1, 2, 2)\" - Crée la deuxième sous-figure pour l'histogramme des hauteurs.\n",
    "<br> Le reste des commandes est similaire, sauf que l'histogramme est basé sur les hauteurs et est coloré en vert.\n",
    "<br>\n",
    "<br> > Ajustement et affichage\n",
    "<br>\n",
    "<br> \"plt.tight_layout()\" - Cette fonction ajuste automatiquement les espacements entre les sous-figures pour éviter que les éléments ne se chevauchent.\n",
    "<br> \"plt.show()\" - Affiche les histogrammes.\n",
    "<br>\n",
    "<br> > Appel de la fonction\n",
    "<br>\n",
    "<br> La fonction est ensuite appelée avec \"PATH_PHOTO_FOLDER\", qui est une variable définie précédemment, représentant le chemin vers le dossier contenant les images de type photo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Informations sur les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_info(folder):\n",
    "    images = os.listdir(folder)\n",
    "    length = len(images)\n",
    "    return length\n",
    "\n",
    "photo_length = get_folder_info(PATH_PHOTO_FOLDER)\n",
    "print(f'Nombre d\\'images dans le dossier photo: {photo_length}')\n",
    "\n",
    "no_photo_len = 0\n",
    "no_photo_folders_len = []\n",
    "for folder in PATH_NO_PHOTO_FOLDERS:\n",
    "    no_photo_folder_len = get_folder_info(folder)\n",
    "    no_photo_len += no_photo_folder_len\n",
    "    no_photo_folders_len.append(no_photo_folder_len)\n",
    "print(f'Nombre d\\'images dans les dossiers sans photo: {no_photo_len}')\n",
    "for i in range(len(PATH_NO_PHOTO_FOLDERS)):\n",
    "    print(f'Nombre d\\'images dans le dossier {PATH_NO_PHOTO_FOLDERS[i]}: {no_photo_folders_len[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Détails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> > Fonction \"get_folder_info(folder)\"\n",
    "<br>\n",
    "<br> \"os.listdir(folder)\" - Cette fonction liste tous les fichiers présents dans le dossier spécifié par le chemin folder.\n",
    "<br> \"len(images)\" - On utilise \"len()\" pour compter combien de fichiers sont dans ce dossier. La fonction retourne cette longueur (length) qui correspond au nombre d'éléments (fichiers ou images) présents dans le dossier.\n",
    "<br>\n",
    "<br> > Compter le nombre d'images dans le dossier de photos\n",
    "<br>\n",
    "<br> \"photo_length = get_folder_info(PATH_PHOTO_FOLDER)\" - Cette ligne appelle la fonction get_folder_info() avec comme argument \"PATH_PHOTO_FOLDER\", qui est le chemin vers le dossier contenant les photos (défini auparavant). Le résultat est stocké dans la variable photo_length, qui contient le nombre total de fichiers (images) dans le dossier de photos.\n",
    "<br> Affichage -  La fonction print() affiche ensuite ce nombre avec un message clair : \"Nombre d'images dans le dossier photo: [nombre]\".\n",
    "<br>\n",
    "<br> > Compter le nombre d'images dans les dossiers sans photos\n",
    "<br>\n",
    "<br> \"no_photo_len = 0\" - Cette variable est initialisée à 0 et servira à accumuler le nombre total d'images dans tous les dossiers sans photos.\n",
    "<br> \"no_photo_folders_len = []\" - C'est une liste vide qui stockera le nombre d'images par dossier sans photos, un par un, pour chaque dossier dans PATH_NO_PHOTO_FOLDERS.\n",
    "<br> \"for folder in PATH_NO_PHOTO_FOLDERS\" -  Cette boucle parcourt chaque dossier dans la liste \"PATH_NO_PHOTO_FOLDERS\", qui contient les chemins vers les dossiers sans photos.\n",
    "<br> \"no_photo_folder_len = get_folder_info(folder)\" - À chaque itération, on appelle la fonction \"get_folder_info()\" pour obtenir le nombre d'images dans le dossier actuel (folder).\n",
    "<br> \"no_photo_len += no_photo_folder_len\" - Le nombre d'images dans chaque dossier est ajouté à \"no_photo_len\", qui cumule le total des images dans tous les dossiers sans photos.\n",
    "<br> \"no_photo_folders_len.append(no_photo_folder_len)\" - Le nombre d'images de chaque dossier est également ajouté à la liste \"no_photo_folders_len\", pour conserver une trace du nombre d'images par dossier séparément.\n",
    "<br> \"print(f'Nombre d\\'images dans les dossiers sans photo: {no_photo_len}')\" - Cette ligne affiche le nombre total d'images dans tous les dossiers sans photos.\n",
    "<br> \"for i in range(len(PATH_NO_PHOTO_FOLDERS))\" - Cette boucle parcourt tous les dossiers sans photos en utilisant leurs indices (basé sur la longueur de PATH_NO_PHOTO_FOLDERS). \n",
    "<br> À chaque itération, elle affiche le nombre d'images correspondant à chaque dossier à l'aide des listes PATH_NO_PHOTO_FOLDERS (pour le nom du dossier) et no_photo_folders_len (pour le nombre d'images dans ce dossier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Générateur du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator(Sequence):\n",
    "    def _getshuffle(self, lenght, start, stop):\n",
    "        global indices\n",
    "        if len(indices) == 0 :\n",
    "            indices = np.arange(lenght)\n",
    "            np.random.shuffle(indices)\n",
    "        return np.array(indices[start:stop])\n",
    "        \n",
    "    def __init__(self, ensemble, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        def find_paths(folder_path, label):\n",
    "            paths = []\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(folder_path, filename)\n",
    "                    paths.append(img_path)\n",
    "            labels = [label] * len(paths)\n",
    "            return paths, labels\n",
    "        \n",
    "        x_path, y = [], []\n",
    "        temp_x_path, temp_y = find_paths(PATH_PHOTO_FOLDER, 1)\n",
    "        x_path += temp_x_path\n",
    "        y += temp_y\n",
    "        \n",
    "        for path in PATH_NO_PHOTO_FOLDERS :\n",
    "            temp_x_path, temp_y = find_paths(path, 0)\n",
    "            x_path += temp_x_path\n",
    "            y += temp_y\n",
    "        \n",
    "        lenght_dataset = len(y)\n",
    "        \n",
    "        if ensemble == 'train' :\n",
    "            start = int(START_TRAIN * lenght_dataset)\n",
    "            stop = int(STOP_TRAIN * lenght_dataset)\n",
    "        elif ensemble == 'val' :\n",
    "            start = int(START_VAL * lenght_dataset)\n",
    "            stop = int(STOP_VAL * lenght_dataset)\n",
    "        elif ensemble == 'test' :\n",
    "            start = int(START_TEST * lenght_dataset)\n",
    "            stop = int(STOP_TEST * lenght_dataset)\n",
    "\n",
    "        self.indices = self._getshuffle(lenght_dataset, start, stop)\n",
    "        self.x_path, self.y = x_path, np.array(y)\n",
    "        \n",
    "        print(f'Taille du générateur de l\\'ensemble {ensemble} = {len(self)}')\n",
    "        print(f'Nombre d\\'images dans le générateur = {len(self.indices)}')\n",
    "        count_photo_generator = np.sum(self.y[self.indices] == 1)\n",
    "        count_no_photo_generator = np.sum(self.y[self.indices] == 0)\n",
    "        print(f'Nombre de photos dans le générateur = {count_photo_generator}')\n",
    "        print(f'Nombre de non photos dans le générateur = {count_no_photo_generator}')\n",
    "              \n",
    "    def __getitem__(self, index):\n",
    "        start_index = index * BATCH_SIZE\n",
    "        stop_index = (index + 1 ) * BATCH_SIZE\n",
    "        chosen_indices = self.indices[start_index:stop_index]\n",
    "        \n",
    "        x, y = [], []\n",
    "        \n",
    "        for indice in chosen_indices :\n",
    "            indice_path = self.x_path[indice]\n",
    "            indice_label = self.y[indice]\n",
    "            with Image.open(indice_path) as img:\n",
    "                img = img.resize((WIDTH, HEIGHT))\n",
    "                img = img.convert('RGB')\n",
    "                x.append(img)\n",
    "            y.append(indice_label)\n",
    "        \n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indices) / BATCH_SIZE))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "train_generator = DatasetGenerator('train', use_multiprocessing=True, workers=6)\n",
    "print('---------------------------------')\n",
    "val_generator = DatasetGenerator('val', use_multiprocessing=True, workers=6)\n",
    "print('---------------------------------')\n",
    "test_generator = DatasetGenerator('test', use_multiprocessing=True, workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Détails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> > Méthode _getshuffle\n",
    "<br>\n",
    "<br>Cette méthode sert à mélanger les indices des images de manière aléatoire. Cela permet de ne pas utiliser les images dans l'ordre où elles apparaissent dans le dossier, pour éviter que l'ordre affecte l'entraînement du modèle.\n",
    "<br> \"np.arange(lenght)\" - Crée une liste d'indices, de 0 à lenght-1.\n",
    "<br> \"np.random.shuffle(indices)\" - Mélange ces indices de manière aléatoire. \n",
    "<br> Cette méthode retourne les indices correspondant à la portion du dataset définie par start et stop (utile pour sélectionner des sous-ensembles : entraînement, validation, ou test).\n",
    "<br>\n",
    "<br> > Constructeur __init__\n",
    "<br>\n",
    "<br> \"__init__ \" est le constructeur de la classe. Il initialise les variables et configurations pour le générateur.\n",
    "<br> Le paramètre \"ensemble\" détermine quel sous-ensemble des données (entraînement, validation ou test) sera traité.\n",
    "<br>\n",
    "<br> - Fonction find_paths pour obtenir les chemins des images\n",
    "<br> Cette fonction parcourt un dossier donné et récupère tous les chemins d'accès des images (PNG, JPG, JPEG).\n",
    "<br> \"label\" - On assigne un label aux images du dossier (1 pour les photos, 0 pour les non-photos).\n",
    "<br> \"paths\" - La fonction retourne une liste des chemins des images ainsi qu’une liste des labels correspondants.\n",
    "<br>\n",
    "<br> - Chargement des chemins des images et labels\n",
    "<br> \"x_path\" et \"y\" stockent les chemins des images et leurs labels respectifs.\n",
    "<br> La fonction find_paths est appelée pour le dossier photo (label = 1) et pour les dossiers sans photo (label = 0). Les chemins et labels sont ajoutés aux listes.\n",
    "<br>\n",
    "<br> - Sélection du sous-ensemble (train, val, test)\n",
    "<br>En fonction de l'argument ensemble (soit 'train', 'val' ou 'test'), on définit les indices de départ et d'arrêt (start et stop) pour sélectionner une portion des données. Ces portions sont définies par les ratios TRAIN_RATIO, VAL_RATIO, et TEST_RATIO spécifiés auparavant.\n",
    "<br>\n",
    "<br> - Shuffle et stockage des données\n",
    "<br>Les indices sont mélangés pour sélectionner la portion du dataset correspondante (entraînement, validation ou test).\n",
    "<br> \"self.x_path\" et \"self.y\" stockent les chemins des images et leurs labels.\n",
    "<br>\n",
    "<br> - Affichage d’informations\n",
    "<br>Cette partie affiche des informations sur le nombre d'images photos et non-photos présentes dans la portion sélectionnée du dataset.\n",
    "<br>\n",
    "<br> > Méthode __getitem__\n",
    "<br>\n",
    "<br> \"__getitem__\" renvoie un batch d'images et leurs labels. Il récupère les indices pour le batch spécifié, charge les images, les redimensionne (256x256), et les convertit en 3 canaux RGB avant de les retourner sous forme de tableaux NumPy (x, y).\n",
    "<br>\n",
    "<br> > Méthode __len__\n",
    "<br> \n",
    "<br> Cette méthode renvoie le nombre total de batches pour un epoch (entraînement complet du dataset).\n",
    "<br>\n",
    "<br> > Méthode on_epoch_end\n",
    "<br>\n",
    "<br> Après chaque epoch, cette méthode est appelée pour remélanger les indices, garantissant une nouvelle répartition aléatoire des données à chaque epoch.\n",
    "<br>\n",
    "<br> > Création des générateurs\n",
    "<br>\n",
    "<br>Les générateurs pour l’entraînement (train), validation (val), et test (test) sont créés. Ils utilisent plusieurs processus (use_multiprocessing=True) et peuvent traiter jusqu’à 6 threads en parallèle (workers=6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = train_generator\n",
    "\n",
    "r_index = r.randint(0, len(generator) - 1)\n",
    "x, y = generator.__getitem__(r_index)\n",
    "print(f'x shape: {x.shape}, y shape: {y.shape}')\n",
    "r_index = r.randint(0, x.shape[0] - 1)\n",
    "plt.imshow(x[r_index])\n",
    "label = 'Photo' if y[r_index] == 1 else 'No photo'\n",
    "plt.title(label)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Détails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> > Choix du générateur\n",
    "<br>\n",
    "<br> \"generator = train_generator\" - Le générateur choisi est celui de l'ensemble d'entraînement, ici train_generator. Un générateur est un objet de type DatasetGenerator (défini précédemment), qui permet de charger des images par lots (batches).\n",
    "<br>\n",
    "<br> > Sélection d'un batch aléatoire\n",
    "<br>\n",
    "<br> \"r_index = r.randint(0, len(generator) - 1)\" :\n",
    "<br>\"r.randint(0, len(generator) - 1)\" - Génère un nombre entier aléatoire compris entre 0 et le nombre total de batches dans le générateur \"(len(generator)\" renvoie ce nombre. Ce nombre correspond à un index aléatoire pour choisir un batch spécifique parmi tous les batches du générateur.\n",
    "<br>\n",
    "<br>\"x, y = generator.__getitem__(r_index)\" :\n",
    "<br>\"generator.__getitem__(r_index)\" - Appelle la méthode \"__getitem__()\" du générateur, qui renvoie un batch d'images (x) et leurs labels associés (y) pour l'index r_index. x est un tableau NumPy contenant les images du batch. y est un tableau NumPy contenant les labels associés à chaque image (1 pour \"Photo\", 0 pour \"No photo\").\n",
    "<br>\n",
    "<br> > Affichage des dimensions des images et labels\n",
    "<br>\n",
    "<br> \"print(f'x shape: {x.shape}, y shape: {y.shape}')\" - Cette ligne affiche les dimensions de x et y pour vérifier que les images et les labels ont la bonne forme. \n",
    "<br>\"x.shape\" - Donne les dimensions du batch d'images.\n",
    "<br>\"y.shape\" - Donne la forme du tableau des labels.\n",
    "<br>\n",
    "<br> > Sélection d'une image aléatoire dans le batch\n",
    "<br>\n",
    "<br>\"r_index = r.randint(0, x.shape[0] - 1)\" - Cette ligne sélectionne un index aléatoire parmi les images du batch (x).\n",
    "<br>\"x.shape[0]\" correspond au nombre d'images dans le batch (égal à BATCH_SIZE).\n",
    "<br>\"plt.imshow(x[r_index])\" - Utilise Matplotlib pour afficher l'image située à l'index aléatoire r_index dans le batch x.\n",
    "<br>\n",
    "<br> > Détermination du label et affichage\n",
    "<br>\n",
    "<br> \"label = 'Photo' if y[r_index] == 1 else 'No photo'\" -  Cette ligne détermine le label de l'image affichée :\n",
    "<br> Si le label y[r_index] (correspondant à l'image x[r_index]) est égal à 1, alors l'image est une photo.\n",
    "<br> Sinon, l'image est étiquetée comme \"No photo\".\n",
    "<br>\"plt.title(label)\" - Ajoute le label comme titre au-dessus de l'image affichée.\n",
    "<br>\"plt.axis('off')\" - Désactive les axes pour que l'image soit affichée sans bordures ni étiquettes.\n",
    "<br>\"plt.show()\" - Affiche l'image et son titre dans une fenêtre graphique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle\n",
    "\n",
    "Dans cette section, nous allons aborder la gestion et l'entraînement du modèle de classification d'images. Tout d'abord, nous verrons comment charger directement un modèle pré-entraîné (fichier Livrable1.h5) pour simplifier le processus. Ensuite, pour les cas où le modèle n'a pas encore été créé, nous détaillerons les différentes étapes de sa construction, incluant notamment la définition des couches. Par la suite, nous procéderons à l'entraînement du modèle sur les données et à l'évaluation de sa performance à l'aide de courbes de précision, de perte, etc. Enfin, nous verrons comment sauvegarder le modèle entraîné pour une potentielle réutilisation future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement d'un modèle préexistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(\"drive/My Drive/Livrable1.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Détails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> > Chargement du modèle\n",
    "<br>\"load_model(\"drive/My Drive/Livrable1.h5\")\" - Cette fonction load_model de la bibliothèque Keras permet de charger le modèle qui a été préalablement sauvegardé dans un fichier .h5. Le fichier contient les poids du modèle, la structure du réseau de neurones (architecture), ainsi que d'éventuelles configurations d'entraînement (comme l'optimiseur). Une fois chargé, le modèle est stocké dans la variable \"model\".\n",
    "<br>\n",
    "<br> > Affichage du résumé du modèle\n",
    "<br>\"model.summary()\" - Cette méthode affiche un résumé détaillé de la structure du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    layers.InputLayer(shape=(HEIGHT, WIDTH, CHANNELS)),\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.Conv2D(32, (3, 3), padding='same', strides=2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.Conv2D(64, (3, 3), padding='same', strides=2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.Conv2D(128, (3, 3), padding='same', strides=2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.Conv2D(256, (3, 3), padding='same', strides=2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('leaky_relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "], name='photo_classifier')\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Détails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \"model = tf.keras.models.Sequential([ Cela signifie que les couches du modèle sont empilées les unes après les autres dans un ordre déterminé. Le modèle suit une architecture simple, couche après couche, sans branchements complexes.\n",
    "<br> \n",
    "<br> > Entrée des données et prétraitement\n",
    "<br> \"InputLayer\" - Définit la taille de l'entrée du modèle. Les images en entrée ont les dimensions (HEIGHT, WIDTH, CHANNELS), où :\n",
    "<br> \"HEIGHT\" et \"WIDTH\" sont les dimensions des images (par exemple, 256x256 pixels),\n",
    "<br> \"CHANNELS\" est le nombre de canaux de couleurs (généralement 3 pour les images RGB).\n",
    "<br> \"Rescaling(1./255)\" - Cette couche normalise les pixels des images. Les valeurs des pixels, qui sont initialement dans la plage [0, 255], sont transformées en valeurs comprises entre [0, 1] en divisant par 255. Cela facilite l'entraînement des réseaux de neurones.\n",
    "<br>\n",
    "<br> > Convulution et normalisation\n",
    "<br>\"Conv2D(32, (3, 3), padding='same', strides=2)\" - 32 filtres sont appliqués à l'image avec des kernels de 3x3. Cela génère 32 cartes de caractéristiques.\n",
    "<br> \"padding='same'\" -  Garantit que la sortie a la même taille spatiale que l'entrée en ajoutant du remplissage si nécessaire.\n",
    "<br> \"strides=2\" -  Réduit la taille de l'image de moitié (downsampling) après chaque convolution.\n",
    "<br> \"BatchNormalization()\" - Cette couche normalise les activations après la convolution. Cela accélère l'entraînement et rend le modèle plus stable.\n",
    "<br> \"Activation('leaky_relu')\" : Applique la fonction d'activation Leaky ReLU, qui permet aux petites valeurs négatives de passer à travers, évitant ainsi le \"dying ReLU problem\" où les neurones peuvent se bloquer.\n",
    "<br> Trois autres couches de convolution sont ajoutées successivement, chacune augmentant le nombre de filtres (64, 128, puis 256) pour capturer des caractéristiques de plus en plus complexes. Les strides=2 après chaque couche continuent à réduire progressivement la taille spatiale de l'image, tout en augmentant le nombre de canaux de caractéristiques.\n",
    "<br> \n",
    "<br> > Flattening et couches denses\n",
    "<br>\n",
    "<br>\"Flatten()\" - Aplatie les cartes de caractéristiques 2D (provenant des convolutions) en un vecteur 1D. Cela prépare les données pour les couches entièrement connectées (couches denses).\n",
    "<br>\"Dense(128)\" - Ajoute une couche entièrement connectée avec 128 neurones. Chaque neurone est connecté à toutes les sorties de la couche précédente.\n",
    "<br>\"BatchNormalization()\" - Normalise les activations dans la couche dense.\n",
    "<br>\"Activation('leaky_relu')\" - Applique la fonction d'activation Leaky ReLU.\n",
    "<br>\"Dropout(0.3)\" - Ajoute du dropout avec un taux de 30%, c'est-à-dire qu'elle désactive aléatoirement 30% des neurones pendant l'entraînement. Cela aide à prévenir le surapprentissage (overfitting).\n",
    "<br>\n",
    "<br> > Couche de sortie\n",
    "<br> \"Dense(1)\" - La dernière couche contient un seul neurone de sortie, car il s'agit d'une classification binaire (deux classes : \"Photo\" ou \"No photo\").\n",
    "<br>\"activation='sigmoid'\" - La fonction d'activation sigmoid est utilisée pour produire une sortie entre 0 et 1, représentant la probabilité que l'image appartienne à la classe \"Photo\".\n",
    "<br>\n",
    "<br> > Compilation du modèle\n",
    "<br>\"optimizer='adam'\" - Utilise l'algorithme Adam comme optimiseur, qui est un optimiseur adaptatif bien adapté aux tâches de classification d'images.\n",
    "<br>\"loss='binary_crossentropy'\" - Utilise la perte d'entropie croisée binaire, appropriée pour les tâches de classification binaire.\n",
    "<br>\"metrics=['accuracy']\" - Le modèle sera évalué en utilisant la précision comme métrique d'évaluation, ce qui correspond au pourcentage de prédictions correctes.\n",
    "<br>\n",
    "<br> > Résumé du modèle\n",
    "<br>\"model.summary()\" - Affiche un résumé complet de l'architecture du modèle, y compris les dimensions de chaque couche et le nombre total de paramètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback d'early stopping\n",
    "early_callback = callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True)\n",
    "\n",
    "# Cycle d'entrainement\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS, callbacks=[early_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Détails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> > Callback d'early stopping\n",
    "<br>Le callback d'early stopping est un mécanisme qui permet de stopper l'entraînement avant d'atteindre le nombre maximal d'époques si le modèle ne s'améliore plus. Il est conçu pour éviter le surapprentissage (ou overfitting) lorsque le modèle commence à suradapter les données d'entraînement, mais ne s'améliore plus sur les données de validation.\n",
    "<br>\"monitor='val_loss'\" - Surveille la performance du modèle en fonction de la perte sur le jeu de validation (val_loss). Cela signifie que si la perte sur les données de validation (un indicateur de la généralisation du modèle) cesse de s'améliorer, le callback entre en action.\n",
    "<br>\"patience=PATIENCE\" : Définit combien d'époques consécutives sans amélioration de la val_loss sont tolérées avant d'arrêter l'entraînement. Le modèle continuera de s'entraîner pendant cette période de patience avant d'interrompre l'entraînement.\n",
    "<br>\"restore_best_weights=True\" - Lorsque l'entraînement est arrêté, les meilleurs poids (ceux qui ont donné la meilleure val_loss pendant l'entraînement) sont automatiquement restaurés. Cela garantit que les poids du modèle final correspondent à la meilleure performance atteinte sur les données de validation, même si l'entraînement a continué après ce point optimal.\n",
    "<br>\n",
    "<br> > Cycle d'entraînement\n",
    "<br>Le cycle d'entraînement est défini par l'appel à la méthode fit() du modèle, qui lance le processus d'apprentissage.\n",
    "<br>\"train_generator\" -  Le générateur d'entraînement qui fournit les images et leurs étiquettes en lots (batchs). Ce générateur permet d'entraîner le modèle sur les données d'entraînement de manière efficace, en particulier lorsque le dataset est trop grand pour être entièrement chargé en mémoire.\n",
    "<br>\"validation_data=val_generator\" - Le générateur de validation qui fournit les données utilisées pour évaluer la performance du modèle à chaque époque. Cela permet de suivre l'évolution de la capacité du modèle à généraliser sur un ensemble de données distinctes (validation) pendant l'entraînement.\n",
    "<br>\"epochs=EPOCHS\" - Définit le nombre maximum d'époques que le modèle peut parcourir lors de l'entraînement. Une époque est un passage complet à travers toutes les données d'entraînement. Si l'early stopping est activé, l'entraînement peut s'arrêter avant d'atteindre ce nombre maximal d'époques.\n",
    "<br>\"callbacks=[early_callback]\" - Le callback d'early stopping est passé en argument. Cela permet à Keras de surveiller la performance du modèle pendant l'entraînement et d'arrêter ce dernier si les conditions d'early stopping sont remplies (dans ce cas, si la val_loss ne s'améliore plus pendant PATIENCE époques)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amélioration bias / variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons utilisé précédement deux techniques pour améliorer cette realtion entre le biais et la vairance. En premier lieu, nous avons appliqué un \"dropout\" ainsi que des \"batch normalisation\" lors de la création du modèle, puis lors de l'entrainement de ce même modèle nous avons mis en place un \"early-stopping\". A quoi servent ces fonctionnalités et pourquoi les implémentées ? Voyons cela plus en détails :\n",
    "<br>\n",
    "<br>Tout d'abord le \"__dropout__\" est une technique de régularisation utilisée dans les réseaux de neurones pour prévenir le surapprentissage (overfitting). L'idée principale derrière le Dropout est d'introduire une forme d'aléatoire dans le réseau pendant l'entraînement afin de rendre le modèle plus robuste et moins dépendant de certaines connexions ou neurones spécifiques.\n",
    "<br>Pendant chaque étape d'entraînement, un pourcentage spécifié de neurones est \"désactivé\" ou ignoré de manière aléatoire. Cela signifie que ces neurones ne contribuent ni à la propagation avant (calcul de la sortie) ni à la rétropropagation (mise à jour des poids).\n",
    "Si un neurone est \"dropout\", sa sortie est ignorée pour cette itération d'entraînement. A chaque itération d'entraînement, les neurones désactivés sont choisis de manière différente, de sorte que différentes parties du réseau apprennent à compenser les autres. Cela empêche le réseau de devenir trop dépendant de certaines connexions ou neurones, ce qui améliore la généralisation du modèle.\n",
    "<br>\n",
    "<br> Dans un second temps, lors de l'entrainement, on peut voir une fonctionnalité d'__early-stopping__. Encore une fois,le but de cette dernière est d'éviter le surapprentissage; en effet, cette méthode permet d'arrêter l'entraînement du modèle de manière anticipée lorsque les performances sur les données de validation cessent de s'améliorer, même si le nombre total d'epochs spécifié n'a pas été atteint.\n",
    "<br>Durant l'entraînement d'un modèle, après chaque epoch (cycle d'entraînement), les performances du modèle sont évaluées à la fois sur les données d'entraînement et sur les données de validation.\n",
    "<br>Au début de l'entraînement, la performance du modèle sur les deux ensembles (entraînement et validation) s'améliore généralement.\n",
    "<br>Cependant, après un certain point, le modèle commence à mémoriser les données d'entraînement (c'est-à-dire qu'il s'adapte trop spécifiquement à ces données) au lieu d'apprendre des caractéristiques généralisables. Cela provoque une dégradation des performances sur les données de validation, même si les performances sur les données d'entraînement continuent de s'améliorer.\n",
    "<br>Early Stopping interrompt l'entraînement dès que les performances sur les données de validation cessent de s'améliorer pendant un certain nombre d'epochs consécutifs, appelé patience.\n",
    "<br>\n",
    "<br>Aussi, la __Batch Normalization__ est une technique qui normalise les activations des couches pendant l'entraînement, en les recentrant et en les échelonnant. Cela aide à stabiliser et à accélérer l'entraînement des réseaux de neurones, tout en ayant un léger effet de régularisation car elle ajoute un bruit à l'entraînement.\n",
    "<br>\n",
    "<br>De plus de ces trois premières techniques implémentées, il en exsite d'autres qui sont considérées comme plus classique (__L1 & L2 regularization__) qui ont le même but que celle déjà mise en place : éviter le surapprentissage. Elles fonctionnent de la façon suivante : \n",
    "ces techniques ajoutent une pénalité à la fonction de perte du modèle basée sur la taille des poids (coefficients) du modèle. Elles encouragent le modèle à avoir des poids plus petits, rendant le modèle plus simple et plus robuste.\n",
    "<br>\n",
    "<br> Enfin on peut penser à différentes méthodes pour limiter grandemment le surapprentissage telles que le __data-augmentation__ qui consiste à augmenter artificiellement la taille du jeu de données en appliquant des transformations aléatoires aux exemples d'entraînement (par exemple, rotation, zoom, inversion, ajout de bruit). Cela permet au modèle de voir des versions modifiées des données originales et de généraliser davantage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Courbes d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Courbes](https://raw.githubusercontent.com/THEDOCTOR015/CESI_A5_DS/refs/heads/main/courbes_%20livrable_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Détails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> > Création de la figure avec deux sous-graphiques\n",
    "<br>\"plt.figure(figsize=(12, 5))\" - Crée une figure avec une taille de 12 pouces de large et 5 pouces de haut, pour afficher deux graphiques côte à côte : l'évolution de la perte et celle de la précision.\n",
    "<br>\n",
    "<br> > Tracé de la courbe de perte\n",
    "<br>\"plt.subplot(1, 2, 1)\" - Crée un sous-graphe, le premier d'une grille de 1 ligne et 2 colonnes (1, 2), où l'on va tracer la courbe de la perte.\n",
    "<br>\"plt.plot(history.history['loss'], label='Training Loss')\" - Trace la courbe de la perte d'entraînement pour chaque époque. Les valeurs de perte sont accessibles via \"history.history['loss']\", où history contient l'historique de l'entraînement du modèle.\n",
    "<br>\"plt.plot(history.history['val_loss'], label='Validation Loss')\" - Trace la courbe de la perte de validation pour chaque époque à partir de history.history['val_loss'].\n",
    "<br>\"plt.title(), plt.xlabel(), plt.ylabel()\" - Définit respectivement le titre du graphique, l'étiquette de l'axe des abscisses (nombre d'époques) et des ordonnées (valeur de la perte).\n",
    "<br>\"plt.legend()\" - Ajoute une légende pour différencier les courbes d'entraînement et de validation.\n",
    "<br>\n",
    "<br> > Tracé de la courbe de précision\n",
    "<br>\"plt.subplot(1, 2, 2)\" - Crée un second sous-graphe pour tracer la précision.\n",
    "<br>\"plt.plot(history.history['accuracy'], label='Training Accuracy')\" - Trace la courbe de la précision d'entraînement pour chaque époque à partir de history.history['accuracy'].\n",
    "<br>\"plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\" - Trace la courbe de la précision de validation à partir de history.history['val_accuracy'].\n",
    "<br> Comme pour le graphique précédent, les titres et les axes sont définis, et la légende permet de différencier les deux courbes.\n",
    "<br>\n",
    "<br> > Affichage des deux graphiques côte à côte\n",
    "<br>\"plt.tight_layout()\" - Ajuste automatiquement les espacements entre les sous-graphiques pour éviter qu'ils ne se chevauchent.\n",
    "<br>\"plt.show()\" - Affiche la figure complète avec les deux graphiques côte à côte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment anylser les courbes d'entrainement pour savoir si les résultats présentés sont bons ? \n",
    "<br>Lorsqu'on analyse les courbes d'entraînement d'un modèle de machine learning, il est crucial de comprendre le compromis entre biais et variance, qui est étroitement lié aux phénomènes de sous-apprentissage (underfitting) et de sur-apprentissage (overfitting). Ce compromis reflète l'équilibre entre la simplicité du modèle (lié au biais) et sa capacité à s'adapter aux données (lié à la variance).\n",
    "<br>Le __sous-apprentissage__ survient lorsque le modèle est trop simple pour capturer les tendances sous-jacentes des données. Cela se traduit par un biais élevé, c’est-à-dire que le modèle a une capacité d'apprentissage limitée et fait de grandes erreurs aussi bien sur les données d'entraînement que sur les données de validation.\n",
    "<br>Graphiquement : \n",
    "<br>- Courbe de perte d’entraînement élevée : Le modèle ne parvient pas à bien s’ajuster aux données d’entraînement, ce qui signifie qu'il ne parvient même pas à apprendre correctement à partir de ces données.\n",
    "<br>- Courbe de perte de validation élevée et proche de celle d'entraînement : Les pertes sur les données de validation et d'entraînement sont similaires, ce qui indique que le modèle est trop simple et ne capture pas la complexité des données.\n",
    "<br>- Précision faible sur les deux ensembles (entraînement et validation).\n",
    "<br>\n",
    "<br>Le __sur-apprentissage__ se produit lorsque le modèle est trop complexe et qu'il commence à mémoriser les données d'entraînement, y compris le bruit et les détails non pertinents. Cela conduit à un écart important entre les performances sur l'ensemble d'entraînement et l'ensemble de validation, car le modèle devient très spécifique aux données d'entraînement et perd en capacité de généralisation.\n",
    "<br> Graphiquement :\n",
    "<br>- Courbe de perte d’entraînement basse : Le modèle parvient à très bien s’ajuster aux données d'entraînement, parfois avec des pertes extrêmement faibles.\n",
    "<br>- Courbe de perte de validation qui augmente après un certain nombre d'epochs : Cela signifie que, même si le modèle continue de s'améliorer sur l'entraînement, il se détériore sur les données de validation. Cela indique que le modèle a commencé à \"mémoriser\" les données d’entraînement plutôt que d'apprendre des généralisations utiles.\n",
    "<br>- Précision d’entraînement très élevée, mais précision de validation beaucoup plus basse : C’est un signe clair de sur-apprentissage.\n",
    "<br>\n",
    "<br>Un __bon compromis__ est atteint lorsque le modèle parvient à bien capturer les relations sous-jacentes des données d'entraînement sans sur-apprendre. Les courbes doivent montrer une convergence stable entre les erreurs d’entraînement et de validation, avec des performances relativement élevées sur les deux ensembles.\n",
    "<br> Graphiquement : \n",
    "<br>- Courbe de perte d’entraînement faible mais pas parfaitement basse : Cela montre que le modèle apprend bien, mais sans mémoriser.\n",
    "<br>- Courbe de perte de validation qui suit la courbe d’entraînement de près : Une petite différence entre les deux courbes est acceptable, mais une divergence rapide signale un sur-apprentissage.\n",
    "<br>- Précision élevée sur l'ensemble d'entraînement et l'ensemble de validation avec des valeurs proches : Le modèle généralise bien, et les prédictions sont bonnes pour les deux ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Librable1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Dans cette dernière partie, nous allons évaluer la performance du modèle entraîné en utilisant deux approches : d'abord nous analyserons les résultats prédictifs à l'aide d'une matrice de confusion, qui permet de visualiser la répartition des erreurs de classification entre les classes. Ensuite, des tests unitaires seront réalisés pour valider la robustesse et la précision du modèle sur un ensemble de données test, garantissant ainsi qu'il peut être utilisé efficacement dans des scénarios réels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions\n",
    "generator_type = input('Entrer l\\'ensemble de données à tester (train, val, test) : ')\n",
    "if generator_type == 'train' :\n",
    "    generator = train_generator\n",
    "elif generator_type == 'val' :\n",
    "    generator = val_generator\n",
    "elif generator_type == 'test' :\n",
    "    generator = test_generator\n",
    "res_pred = []\n",
    "res_true = []\n",
    "count = 0\n",
    "# Predit batch par batch\n",
    "for x, y in generator:\n",
    "    y_pred = model.predict(x, verbose=0)\n",
    "    y_pred = np.round(y_pred).flatten()\n",
    "    y_pred = y_pred.tolist()\n",
    "    res_pred += y_pred\n",
    "    res_true += y.tolist()\n",
    "    count += 1\n",
    "    print(f'Batch {count} / {len(generator)}')\n",
    "    if count == len(generator) :\n",
    "        break\n",
    "res_pred = np.array(res_pred)\n",
    "res_true = np.array(res_true)\n",
    "\n",
    "# Calcul de la matrice de confusion avec le titre de son ensemble\n",
    "cm = confusion_matrix(res_true, res_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "# Affichage de la matrice de confusion\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No photo', 'Photo'], yticklabels=['No photo', 'Photo'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix - {generator_type} Acc: {precision:.2f}, Rec: {recall:.2f}, F1: {f1:.2f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Détails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> > Choix de l'ensemble de données\n",
    "<br>L'utilisateur est invité à sélectionner un ensemble de données à tester : soit train, val (validation), ou test.\n",
    "Selon le choix, le générateur correspondant est assigné à la variable generator.\n",
    "<br>\n",
    "<br> > Boucle de prédiction batch par batch\n",
    "<br>\"res_pred\" - Liste pour stocker les prédictions du modèle.\n",
    "<br>\"res_true\" - Liste pour stocker les vraies étiquettes des données.\n",
    "<br>La boucle parcourt chaque batch d'images (x) et leurs étiquettes (y) dans le générateur.\n",
    "<br>\"model.predict(x)\" - Le modèle effectue des prédictions sur le batch d'images.\n",
    "<br>\"np.round(y_pred)\" - Les prédictions sont arrondies pour correspondre à des classes binaires (0 ou 1).\n",
    "<br>Les résultats sont ajoutés aux listes res_pred (prédictions) et res_true (vraies étiquettes).\n",
    "<br>\"print(f'Batch {count} / {len(generator)}\" - Affiche l'avancement du traitement des batches.\n",
    "<br>La boucle s'arrête lorsque tous les batches ont été parcourus.\n",
    "<br>\n",
    "<br> > Calcul de la matrice de confusion et des métriques\n",
    "<br>\"confusion_matrix(res_true, res_pred)\" - Calcule la matrice de confusion en comparant les vraies étiquettes (res_true) avec les prédictions (res_pred). Cette matrice contient :\n",
    "\n",
    "    TP (True Positives) : Photos correctement classées.\n",
    "    TN (True Negatives) : Non-photos correctement classées.\n",
    "    FP (False Positives) : Non-photos classées à tort comme photos.\n",
    "    FN (False Negatives) : Photos classées à tort comme non-photos.\n",
    "\"cm.ravel()\" - Permet d'obtenir les valeurs tn, fp, fn, tp directement.\n",
    "<br> Les métriques classiques de classification binaire sont ensuite calculées :\n",
    "\n",
    "    Précision : La proportion de prédictions positives correctes : Précision = TP / (TP + FP)\n",
    "    Rappel : La proportion de vraies positives correctement identifiées : Rappel = TP /(TP + FN)\n",
    "    F1-score : La moyenne harmonique entre précision et rappel : F1 = (2 x (Précision x Rappel)) / (Précision + Rappel)\n",
    "<br> > Affichage de la matrice de confusion\n",
    "<br>\"plt.figure(figsize=(10, 7))\" - Définit la taille de la figure pour la matrice de confusion.\n",
    "<br>\"sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\" - Affiche la matrice de confusion sous forme de heatmap (carte thermique), avec les valeurs annotées dans chaque cellule et une palette de couleurs bleues.\n",
    "<br>\"xticklabels\" et \"yticklabels\" - Les axes sont étiquetés avec \"No photo\" et \"Photo\" pour indiquer les classes.\n",
    "<br>\"plt.title()\" - Le titre de la figure inclut le type d'ensemble de données (train, val, test) et les principales métriques : Précision, Rappel, et F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test unitaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "generator_type = 'val'\n",
    "if generator_type == 'train' :\n",
    "    generator = train_generator\n",
    "elif generator_type == 'val' :\n",
    "    generator = val_generator\n",
    "elif generator_type == 'test' :\n",
    "    generator = test_generator\n",
    "\n",
    "# On récupère une image aléatoirement depuis le générateur\n",
    "r_index = r.randint(0, len(generator.indices) - 1)\n",
    "img_path = generator.x_path[generator.indices[r_index]]\n",
    "label = generator.y[generator.indices[r_index]]\n",
    "label = 'Photo' if label == 1 else 'No photo'\n",
    "\n",
    "# On charge l'image\n",
    "with Image.open(img_path) as img:\n",
    "    img = img.resize((WIDTH, HEIGHT)) # Avoir la même taille\n",
    "    img = img.convert('RGB') # Avoir 3 channels\n",
    "\n",
    "# On fait la prédiction\n",
    "img = np.array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "prediction = model.predict(img)\n",
    "pred_label = 'Photo' if prediction[0][0] > 0.5 else 'No photo'\n",
    "\n",
    "# On affiche les résultats\n",
    "plt.imshow(img[0])\n",
    "plt.title(f'Label: {label}, Prediction: {pred_label}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Détails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> > Sélection du générateur de données\n",
    "<br>\"generator_type = 'val'\" - Définit l'ensemble de données que l'on souhaite utiliser (ici, l'ensemble de validation).\n",
    "<br>Selon la valeur de generator_type, le générateur approprié est sélectionné parmi train_generator, val_generator (validation), ou test_generator.\n",
    "<br>\n",
    "<br> > Sélection aléatoire d'une image\n",
    "<br>\"r.randint(0, len(generator.indices) - 1)\" - Sélectionne un index aléatoire pour choisir une image du générateur.\n",
    "<br>\"generator.x_path\" - Contient les chemins des images dans le générateur.\n",
    "<br>\"generator.indices[r_index]\" - Utilise l'index aléatoire pour récupérer le chemin de l'image correspondante.\n",
    "<br>\"generator.y\" - Contient les labels associés aux images. Ici, si le label est 1, cela signifie que c'est une photo, sinon c'est une non-photo (schéma, croquis, etc.).\n",
    "<br>\"label = 'Photo' if label == 1 else 'No photo'\" - Convertit le label binaire en un label textuel.\n",
    "<br>\n",
    "<br> > Chargement et traitement de l'image\n",
    "<br>\"Image.open(img_path)\" - Charge l'image depuis le chemin sélectionné.\n",
    "<br>\"img.resize((WIDTH, HEIGHT))\" - Redimensionne l'image à la taille standard définie dans les paramètres du modèle (256x256 ici).\n",
    "<br>\"img.convert('RGB')\" - Convertit l'image en RGB, assurant qu'elle possède 3 canaux (Red, Green, Blue), requis par le modèle de classification.\n",
    "<br>\n",
    "<br> > Préparation pour la prédiction\n",
    "<br>\"np.array(img)\" - Convertit l'image en un tableau numpy afin qu'elle puisse être utilisée dans la prédiction.\n",
    "<br>\"np.expand_dims(img, axis=0)\" - Ajoute une dimension supplémentaire en tête du tableau pour former un \"batch\" de taille 1. Les modèles TensorFlow s'attendent à recevoir des données sous forme de batchs, donc même pour une seule image, on doit ajouter cette dimension.\n",
    "<br>\n",
    "<br> > Prédiction du modèle\n",
    "<br>\"model.predict(img)\" - Le modèle prédit la probabilité que l'image soit une photo. Il renvoie une probabilité entre 0 et 1.\n",
    "<br>\"prediction[0][0] > 0.5\" - Si la prédiction est supérieure à 0.5, l'image est classée comme photo, sinon comme non-photo.\n",
    "<br>\"pred_label\" - Stocke le label prédictif textuel.\n",
    "<br>\n",
    "<br> > Affichage de l'image et des résultats\n",
    "<br>\"plt.imshow(img[0])\" - Affiche l'image en utilisant matplotlib.\n",
    "<br>\"plt.title(f'Label: {label}, Prediction: {pred_label}')\" - Affiche le titre contenant à la fois le label réel (ground truth) et la prédiction du modèle.\n",
    "<br>\"plt.axis('off')\" - Désactive les axes pour un affichage plus propre de l'image.\n",
    "<br>\"plt.show()\" - Affiche l'image avec les annotations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
